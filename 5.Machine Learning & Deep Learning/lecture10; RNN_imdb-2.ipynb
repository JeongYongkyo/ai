{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f847546e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:12:33.597321Z",
     "start_time": "2021-06-01T06:12:32.142836Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8056d49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:12:37.432702Z",
     "start_time": "2021-06-01T06:12:33.599027Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piai/anaconda3/envs/abc/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n",
      "(25000,)\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piai/anaconda3/envs/abc/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "top_words = 10000 # 가장 많이쓰이는 단어 10000개\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words = top_words)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test[0]) # 0=negative, 1=positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e14ce5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:12:37.439471Z",
     "start_time": "2021-06-01T06:12:37.435289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32])\n",
      " list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])\n",
      " list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113])\n",
      " ...\n",
      " list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2])\n",
      " list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23])\n",
      " list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])]\n",
      "[1 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd6655a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:12:37.518758Z",
     "start_time": "2021-06-01T06:12:37.441742Z"
    }
   },
   "outputs": [],
   "source": [
    "word_to_index = tf.keras.datasets.imdb.get_word_index()\n",
    "# print(type(word_to_index))\n",
    "# print(word_to_index)\n",
    "\n",
    "index_to_word = {}\n",
    "for key, value in word_to_index.items():\n",
    "    index_to_word[value+3] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab6f1e79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:12:37.524565Z",
     "start_time": "2021-06-01T06:12:37.520442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "and\n",
      "a\n",
      "of\n",
      "to\n"
     ]
    }
   ],
   "source": [
    "for i in range(5): # 제일 많이 쓰인 단어 5개\n",
    "    print(index_to_word[i+4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1df7de7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:12:37.543601Z",
     "start_time": "2021-06-01T06:12:37.526558Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "print(index_to_word[120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c604dfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:12:37.846832Z",
     "start_time": "2021-06-01T06:12:37.545748Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest length of the review : 2494\n",
      "The average length of the review : 238.71364\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_result = [len(s) for s in x_train]\n",
    "#print(len_result)\n",
    "\n",
    "print(\"The longest length of the review : {}\".format(np.max(len_result)))\n",
    "print(\"The average length of the review : {}\".format(np.mean(len_result)))\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(len_result, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64c754a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:12:37.853856Z",
     "start_time": "2021-06-01T06:12:37.848556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]\n",
      "<sos> this has to be one of the worst films of the 1990s when my friends i were watching this film being the target audience it was aimed at we just sat watched the first half an hour with our jaws touching the floor at how bad it really was the rest of the time everyone else in the theatre just started talking to each other leaving or generally crying into their popcorn that they actually paid money they had <unk> working to watch this feeble excuse for a film it must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how <unk> this is to watch save yourself an hour a bit of your life\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for index, token in enumerate((\"<pad>\",\"<sos>\",\"<unk>\")):\n",
    "    index_to_word[index]=token\n",
    "    \n",
    "print(x_train[2])\n",
    "print(' '.join([index_to_word[index] for index in x_train[2]]))\n",
    "print(y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16678cc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:12:38.704885Z",
     "start_time": "2021-06-01T06:12:37.857314Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len = 200\n",
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_len) # 단어가 200개가 넘어가면 자른다.\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05da96a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:12:38.710549Z",
     "start_time": "2021-06-01T06:12:38.706708Z"
    }
   },
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc1 = tf.keras.callbacks.ModelCheckpoint('./data_files/rnn_test', monitor='val_accuracy', mode='max', verbose=1, save_freq='epoch', save_best_only=True)\n",
    "mc2 = tf.keras.callbacks.ModelCheckpoint('./data_files/lstm_test', monitor='val_accuracy', mode='max', verbose=1, save_freq='epoch', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebf1a017",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:12:39.738485Z",
     "start_time": "2021-06-01T06:12:38.711830Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 150)         1500000   \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 64)                13760     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,513,825\n",
      "Trainable params: 1,513,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn = tf.keras.Sequential() # sequence의 길이 max_len(200개) 일정하게 맞춰줌           \n",
    "rnn.add(layers.Embedding(top_words, 150)) # 10000, 150 => 10000개의 단어가 있는데 150(벡터)으로 embedding시킴\n",
    "                                              #           예를들어 one-hot인코딩 하면 10000개의 차원이 생김(각단어의 연관성 없음)\n",
    "                                              #           각단어의 연관성을 고려해서 150개정도의 벡터에서 10000개의 단어를 표현\n",
    "rnn.add(layers.SimpleRNN(64))\n",
    "rnn.add(layers.Dense(1, activation='sigmoid'))\n",
    "rnn.summary()\n",
    "\n",
    "# (None, None, 200)         1500000 = 150*10000  => 단어하나당 150개의 weight * 10000개의 단어\n",
    "\n",
    "# ht = tanh(Wxh*Xt + Whh*ht-1 + b)\n",
    "#           64*150 + 64*64 + 64\n",
    "#           총 param 13760개\n",
    "# dense = Wh + b = 1*64 + 1 = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e4e7417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:15:47.539725Z",
     "start_time": "2021-06-01T06:12:39.740026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.6042 - accuracy: 0.6587\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66380, saving model to ./data_files/rnn_test\n",
      "WARNING:tensorflow:From /home/piai/anaconda3/envs/abc/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./data_files/rnn_test/assets\n",
      "334/334 [==============================] - 38s 113ms/step - loss: 0.6042 - accuracy: 0.6587 - val_loss: 0.6093 - val_accuracy: 0.6638\n",
      "Epoch 2/5\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.4561 - accuracy: 0.7869\n",
      "Epoch 00002: val_accuracy improved from 0.66380 to 0.73620, saving model to ./data_files/rnn_test\n",
      "INFO:tensorflow:Assets written to: ./data_files/rnn_test/assets\n",
      "334/334 [==============================] - 37s 112ms/step - loss: 0.4561 - accuracy: 0.7869 - val_loss: 0.5480 - val_accuracy: 0.7362\n",
      "Epoch 3/5\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.2196 - accuracy: 0.9169\n",
      "Epoch 00003: val_accuracy improved from 0.73620 to 0.81320, saving model to ./data_files/rnn_test\n",
      "INFO:tensorflow:Assets written to: ./data_files/rnn_test/assets\n",
      "334/334 [==============================] - 38s 113ms/step - loss: 0.2196 - accuracy: 0.9169 - val_loss: 0.5118 - val_accuracy: 0.8132\n",
      "Epoch 4/5\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 0.9805\n",
      "Epoch 00004: val_accuracy did not improve from 0.81320\n",
      "334/334 [==============================] - 36s 109ms/step - loss: 0.0647 - accuracy: 0.9805 - val_loss: 0.6179 - val_accuracy: 0.8058\n",
      "Epoch 5/5\n",
      "334/334 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9959\n",
      "Epoch 00005: val_accuracy did not improve from 0.81320\n",
      "334/334 [==============================] - 37s 110ms/step - loss: 0.0188 - accuracy: 0.9959 - val_loss: 0.7891 - val_accuracy: 0.7608\n"
     ]
    }
   ],
   "source": [
    "rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "result = rnn.fit(x_train, y_train, epochs=5, callbacks=[es, mc1], batch_size=60, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9960269",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:16:02.353942Z",
     "start_time": "2021-06-01T06:15:47.541702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 15s 19ms/step - loss: 0.7713 - accuracy: 0.7607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7713456749916077, 0.7606800198554993]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.evaluate(x_test, y_test) # [loss, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ede25e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:16:18.043867Z",
     "start_time": "2021-06-01T06:16:02.356335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 15s 19ms/step - loss: 0.5113 - accuracy: 0.8133\n",
      "[0.5113013982772827, 0.813319981098175]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('data_files/rnn_test')\n",
    "print(loaded_model.evaluate(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba5e6ac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:16:18.055012Z",
     "start_time": "2021-06-01T06:16:18.046904Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def sentiment_predict(new_sentence):\n",
    "    # 알파벳과 숫자를 제외하고 모두 제거 및 알파벳 소문자화\n",
    "    new_sentence = re.sub('[^0-9a-zA-Z ]', '', new_sentence).lower()\n",
    "\n",
    "    # 정수 인코딩\n",
    "    encoded = []\n",
    "    for word in new_sentence.split():\n",
    "    # 단어 집합의 크기를 10,000으로 제한.\n",
    "        try :\n",
    "            if word_to_index[word] <= 10000:\n",
    "                encoded.append(word_to_index[word]+3)\n",
    "            else:\n",
    "        # 10,000 이상의 숫자는 <unk> 토큰으로 취급.\n",
    "                encoded.append(2)\n",
    "        # 단어 집합에 없는 단어는 <unk> 토큰으로 취급.\n",
    "        except KeyError:\n",
    "            encoded.append(2)\n",
    "\n",
    "    pad_new = pad_sequences([encoded], maxlen = max_len) # 패딩\n",
    "    score = float(loaded_model.predict(pad_new)) # 예측\n",
    "    if(score > 0.5):\n",
    "        print(\"positive with the probability {:.2f}% .\".format(score * 100))\n",
    "    else:\n",
    "        print(\"negative with the probability {:.2f}% \".format((1 - score) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36d5afae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:25:54.053341Z",
     "start_time": "2021-06-01T06:25:54.000122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive with the probability 61.79% .\n"
     ]
    }
   ],
   "source": [
    "my_review=\"Hello this is the best movie i have ever seen, but it was just before the end of the movie. The last scene was really disgusting\"\n",
    "sentiment_predict(my_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46663ada",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:16:18.535034Z",
     "start_time": "2021-06-01T06:16:18.295203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 1,042,370\n",
      "Trainable params: 1,042,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = tf.keras.Sequential()\n",
    "lstm.add(layers.Embedding(top_words, 100))\n",
    "lstm.add(layers.LSTM(64))\n",
    "lstm.add(layers.Dense((2), activation='softmax')) # 0, 1 \n",
    "lstm.summary()\n",
    "\n",
    "# (None, None, 100)         1000000 = 100*10000  => 단어하나당 100개의 weight * 10000개의 단어\n",
    "\n",
    "# ht = tanh(Wxh*Xt + Whh*ht-1 + b) * f, i, c, o\n",
    "#           (64*100 + 64*64 + 64) * 4\n",
    "#           총 param 42240개\n",
    "# dense = Wh + b = 1*64 + 1 = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2818ea2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:18:10.816608Z",
     "start_time": "2021-06-01T06:16:18.536607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train LSTM\n",
      "Epoch 1/5\n",
      "1248/1250 [============================>.] - ETA: 0s - loss: 0.4337 - accuracy: 0.7985\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.83120, saving model to ./data_files/lstm_test\n",
      "INFO:tensorflow:Assets written to: ./data_files/lstm_test/assets\n",
      "1250/1250 [==============================] - 24s 19ms/step - loss: 0.4336 - accuracy: 0.7986 - val_loss: 0.4350 - val_accuracy: 0.8312\n",
      "Epoch 2/5\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.2707 - accuracy: 0.8912\n",
      "Epoch 00002: val_accuracy improved from 0.83120 to 0.86420, saving model to ./data_files/lstm_test\n",
      "INFO:tensorflow:Assets written to: ./data_files/lstm_test/assets\n",
      "1250/1250 [==============================] - 23s 18ms/step - loss: 0.2708 - accuracy: 0.8911 - val_loss: 0.3256 - val_accuracy: 0.8642\n",
      "Epoch 3/5\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.1794 - accuracy: 0.9333\n",
      "Epoch 00003: val_accuracy improved from 0.86420 to 0.87280, saving model to ./data_files/lstm_test\n",
      "INFO:tensorflow:Assets written to: ./data_files/lstm_test/assets\n",
      "1250/1250 [==============================] - 23s 19ms/step - loss: 0.1794 - accuracy: 0.9334 - val_loss: 0.3550 - val_accuracy: 0.8728\n",
      "Epoch 4/5\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.1192 - accuracy: 0.9558\n",
      "Epoch 00004: val_accuracy did not improve from 0.87280\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 0.1193 - accuracy: 0.9558 - val_loss: 0.4384 - val_accuracy: 0.8694\n",
      "Epoch 5/5\n",
      "1249/1250 [============================>.] - ETA: 0s - loss: 0.0830 - accuracy: 0.9714\n",
      "Epoch 00005: val_accuracy did not improve from 0.87280\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 0.0830 - accuracy: 0.9714 - val_loss: 0.5291 - val_accuracy: 0.8684\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efc192df2e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.compile(optimizer ='adam', loss ='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"Train LSTM\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1, stratify=y_train) #y_train값의 값을 기준으로\n",
    "\n",
    "lstm.fit(x_train, y_train, epochs=5, callbacks=[es, mc2], batch_size=16, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17e15b03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:18:16.263284Z",
     "start_time": "2021-06-01T06:18:10.820150Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 7ms/step - loss: 0.5642 - accuracy: 0.8576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5642160177230835, 0.8575999736785889]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47c38def",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:18:23.690230Z",
     "start_time": "2021-06-01T06:18:16.265783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3863 - accuracy: 0.8613\n",
      "[0.3863230049610138, 0.8612800240516663]\n"
     ]
    }
   ],
   "source": [
    "loaded_model_lstm = tf.keras.models.load_model('data_files/lstm_test')\n",
    "print(loaded_model_lstm.evaluate(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05f524b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:19:18.107681Z",
     "start_time": "2021-06-01T06:18:23.692484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Multi_LSTM\n",
      "Epoch 1/5\n",
      "334/334 [==============================] - 11s 33ms/step - loss: 0.4062 - accuracy: 0.8111 - val_loss: 0.3567 - val_accuracy: 0.8582\n",
      "Epoch 2/5\n",
      "334/334 [==============================] - 10s 31ms/step - loss: 0.2396 - accuracy: 0.9072 - val_loss: 0.2989 - val_accuracy: 0.8786\n",
      "Epoch 3/5\n",
      "334/334 [==============================] - 10s 30ms/step - loss: 0.1524 - accuracy: 0.9445 - val_loss: 0.3856 - val_accuracy: 0.8728\n",
      "Epoch 4/5\n",
      "334/334 [==============================] - 10s 30ms/step - loss: 0.1132 - accuracy: 0.9610 - val_loss: 0.4109 - val_accuracy: 0.8384\n",
      "Epoch 5/5\n",
      "334/334 [==============================] - 10s 30ms/step - loss: 0.1024 - accuracy: 0.9636 - val_loss: 0.4474 - val_accuracy: 0.8640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efc18165a60>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_lstm = tf.keras.Sequential()\n",
    "multi_lstm.add(layers.Embedding(top_words, 160))\n",
    "multi_lstm.add(layers.LSTM(64, return_sequences=True))\n",
    "multi_lstm.add(layers.LSTM(64))\n",
    "multi_lstm.add(layers.Dense(2, activation='softmax'))\n",
    "\n",
    "multi_lstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"Train: Multi_LSTM\")\n",
    "multi_lstm.fit(x_train, y_train, epochs=5, batch_size=60, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da1d5448",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:19:26.927496Z",
     "start_time": "2021-06-01T06:19:18.109359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 9s 11ms/step - loss: 0.5022 - accuracy: 0.8475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5022159218788147, 0.8475199937820435]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_lstm.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c785eb2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:19:27.396463Z",
     "start_time": "2021-06-01T06:19:26.929599Z"
    }
   },
   "outputs": [],
   "source": [
    "bi_lstm = tf.keras.Sequential()\n",
    "bi_lstm.add(layers.Embedding(top_words, 160))\n",
    "\n",
    "lstm_fw = layers.LSTM(64)\n",
    "lstm_bw = layers.LSTM(64, go_backwards=True)\n",
    "\n",
    "bi_lstm.add(layers.Bidirectional(lstm_fw, backward_layer=lstm_bw))\n",
    "bi_lstm.add(layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67ac3a26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:20:20.501914Z",
     "start_time": "2021-06-01T06:19:27.398576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Bidirectional_LSTM\n",
      "Epoch 1/5\n",
      "334/334 [==============================] - 11s 32ms/step - loss: 0.4001 - accuracy: 0.8065 - val_loss: 0.2962 - val_accuracy: 0.8784\n",
      "Epoch 2/5\n",
      "334/334 [==============================] - 10s 31ms/step - loss: 0.2255 - accuracy: 0.9137 - val_loss: 0.3830 - val_accuracy: 0.8436\n",
      "Epoch 3/5\n",
      "334/334 [==============================] - 10s 30ms/step - loss: 0.1478 - accuracy: 0.9451 - val_loss: 0.3576 - val_accuracy: 0.8698\n",
      "Epoch 4/5\n",
      "334/334 [==============================] - 10s 30ms/step - loss: 0.0951 - accuracy: 0.9664 - val_loss: 0.4772 - val_accuracy: 0.8668\n",
      "Epoch 5/5\n",
      "334/334 [==============================] - 10s 30ms/step - loss: 0.0831 - accuracy: 0.9720 - val_loss: 0.4606 - val_accuracy: 0.8562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efc1ae5eac0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_lstm.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
    "print(\"Train: Bidirectional_LSTM\")\n",
    "bi_lstm.fit(x_train, y_train, epochs=5, batch_size=60, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a4771cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T06:20:29.494772Z",
     "start_time": "2021-06-01T06:20:20.505547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 9s 11ms/step - loss: 0.4717 - accuracy: 0.8490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47171133756637573, 0.8489599823951721]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_lstm.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2858e2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
