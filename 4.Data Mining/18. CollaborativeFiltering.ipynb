{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "from itertools import chain\n",
    "from surprise import Dataset, Reader, KNNBasic, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 아래 주어진 평점 DataFrame을 활용하여 Collaborative Filtering을 적용한 결과를 출력하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.DataFrame([\n",
    "    [30878, 1, 4], [30878, 5, 1], [30878, 18, 3], [30878, 28, 3], [30878, 30, 4], [30878, 44, 5], \n",
    "    [124105, 1, 4], \n",
    "    [822109, 1, 5], \n",
    "    [823519, 1, 3], [823519, 8, 1], [823519, 17, 4], [823519, 28, 4], [823519, 30, 5], \n",
    "    [885013, 1, 4], [885013, 5, 5], \n",
    "    [893988, 1, 3], [893988, 30, 4], [893988, 44, 4], \n",
    "    [1248029, 1, 3], [1248029, 28, 2], [1248029, 30, 4], [1248029, 48, 3], \n",
    "    [1503895, 1, 4], \n",
    "    [1842128, 1, 4], [1842128, 30, 3], \n",
    "    [2238063, 1, 3], \n",
    "], columns=['customerID', 'movieID', 'rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid='823519', iid='30', r_ui=None, est=3.5384615384615383, details={'was_impossible': True, 'reason': 'User and/or item is unknown.'})"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(ratings[['customerID', 'movieID', 'rating']], reader)\n",
    "trainset = data.build_full_trainset()\n",
    "sim_options = {'name': 'cosine', 'user_based': False}  # compute cosine similarities between items\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "algo.fit(trainset)\n",
    "pred = algo.predict('823519', '30')\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 아래 랜덤하게 만든 평점 DataFrame을 활용하여 Collaborative Filtering을 적용한 결과를 출력하시오.\n",
    "- 주어진 get_top_n 함수 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>userID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>665</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97</td>\n",
       "      <td>974</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>542</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>634</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>694</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemID  userID  rating\n",
       "0      49     665       1\n",
       "1      97     974       5\n",
       "2      53     542       5\n",
       "3       5     634       3\n",
       "4      33     694       2"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "nratings = 5000\n",
    "randomData = pd.DataFrame({\n",
    "    'itemID': [random.randint(0,99) for _ in range(nratings)],\n",
    "    'userID': [random.randint(0,999) for _ in range(nratings)],\n",
    "    'rating': [random.randint(1,5) for _ in range(nratings)],\n",
    "})\n",
    "randomData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    # First map the predictions to each user.\n",
    "    byUser = defaultdict(list)\n",
    "    for p in predictions:\n",
    "        byUser[p.uid].append(p)\n",
    "    \n",
    "    byUserSorted = {}\n",
    "    for uid in byUser:\n",
    "        byUserSorted[uid] = sorted(byUser[uid], key=lambda x: x.est, reverse=True)[:n]\n",
    "    return byUserSorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- user 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Top-3 recommended items for each user\n",
      "User 6\n",
      "  Item 6 (5.00)  Item 77 (2.50)  Item 60 (1.00)\n",
      "User 222\n",
      "  Item 77 (3.50)  Item 75 (2.78)\n",
      "User 424\n",
      "  Item 14 (3.50)  Item 45 (3.10)  Item 54 (2.34)\n",
      "User 87\n",
      "  Item 27 (3.00)  Item 54 (3.00)  Item 82 (3.00)  Item 32 (1.00)\n",
      "User 121\n",
      "  Item 98 (3.48)  Item 32 (2.83)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert thes data set into the format required by the surprise package\n",
    "# The columns must correspond to user id, item id and ratings (in that order)\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(randomData[['userID', 'itemID', 'rating']], reader)\n",
    "\n",
    "# Split into training and test set\n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=1)\n",
    "\n",
    "## User-based filtering\n",
    "# compute cosine similarity between users \n",
    "sim_options = {'name': 'cosine', 'user_based': True}\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Than predict ratings for all pairs (u, i) that are NOT in the training set.\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "top_n = get_top_n(predictions, n=4)\n",
    "\n",
    "# Print the recommended items for each user\n",
    "print('Top-3 recommended items for each user')\n",
    "for uid, user_ratings in list(top_n.items())[:5]:\n",
    "    print('User {}'.format(uid))\n",
    "    for prediction in user_ratings:\n",
    "        print('  Item {0.iid} ({0.est:.2f})'.format(prediction), end='')\n",
    "    print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.6030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.602978765654451"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- item 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Top-3 recommended items for each user\n",
      "User 6\n",
      "  Item 77 (3.00)  Item 60 (3.00)  Item 6 (3.00)\n",
      "User 222\n",
      "  Item 77 (2.24)  Item 75 (2.00)\n",
      "User 424\n",
      "  Item 54 (3.47)  Item 14 (3.44)  Item 45 (3.00)\n",
      "User 87\n",
      "  Item 27 (3.00)  Item 32 (3.00)  Item 82 (3.00)  Item 54 (2.50)\n",
      "User 121\n",
      "  Item 32 (3.06)  Item 98 (2.31)\n"
     ]
    }
   ],
   "source": [
    "## Item-based filtering\n",
    "# compute cosine similarity between users \n",
    "sim_options = {'name': 'cosine', 'user_based': False}\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Than predict ratings for all pairs (u, i) that are NOT in the training set.\n",
    "predictions = algo.test(testset)\n",
    "top_n = get_top_n(predictions, n=4)\n",
    "\n",
    "# Print the recommended items for each user\n",
    "print()\n",
    "print('Top-3 recommended items for each user')\n",
    "for uid, user_ratings in list(top_n.items())[:5]:\n",
    "    print('User {}'.format(uid))\n",
    "    for prediction in user_ratings:\n",
    "        print('  Item {0.iid} ({0.est:.2f})'.format(prediction), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.7063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.706273729603763"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model-based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SVD 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-3 recommended items for each user\n",
      "User 6\n",
      "  Item 6 (3.26)  Item 60 (3.18)  Item 77 (2.96)\n",
      "User 222\n",
      "  Item 75 (2.86)  Item 77 (2.52)\n",
      "User 424\n",
      "  Item 14 (3.04)  Item 54 (2.98)  Item 45 (2.72)\n",
      "User 87\n",
      "  Item 82 (3.02)  Item 27 (2.93)  Item 54 (2.74)  Item 32 (2.71)\n",
      "User 121\n",
      "  Item 98 (3.23)  Item 32 (3.16)\n"
     ]
    }
   ],
   "source": [
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "predictions = algo.test(testset)\n",
    "top_n = get_top_n(predictions, n=4)\n",
    "\n",
    "# Print the recommended items for each user\n",
    "print()\n",
    "print('Top-3 recommended items for each user')\n",
    "for uid, user_ratings in list(top_n.items())[:5]:\n",
    "    print('User {}'.format(uid))\n",
    "    for prediction in user_ratings:\n",
    "        print('  Item {0.iid} ({0.est:.2f})'.format(prediction), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.4464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4463662780451023"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise 홈페이지: https://surprise.readthedocs.io/en/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo1 = KNNBasic(sim_options={'name': 'cosine', 'user_based': True})\n",
    "algo2 = KNNBasic(sim_options={'name': 'cosine', 'user_based': False})\n",
    "algo3 = SVD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0262  1.0152  1.0138  1.0074  1.0235  1.0173  0.0068  \n",
      "Fit time          0.54    0.55    0.55    0.54    0.54    0.54    0.00    \n",
      "Test time         1.94    1.84    1.95    1.85    1.94    1.90    0.05    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.02624769, 1.01522444, 1.01384497, 1.00744995, 1.02350943]),\n",
       " 'fit_time': (0.5433268547058105,\n",
       "  0.5461905002593994,\n",
       "  0.5468482971191406,\n",
       "  0.541083574295044,\n",
       "  0.5435516834259033),\n",
       " 'test_time': (1.9365429878234863,\n",
       "  1.8359925746917725,\n",
       "  1.9520387649536133,\n",
       "  1.8521714210510254,\n",
       "  1.942430019378662)}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(algo1, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0192  1.0214  1.0319  1.0289  1.0291  1.0261  0.0049  \n",
      "Fit time          0.96    1.01    1.02    0.99    1.01    1.00    0.02    \n",
      "Test time         2.09    2.22    2.11    2.27    2.09    2.16    0.07    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.0192115 , 1.02144182, 1.0318935 , 1.02885539, 1.02910201]),\n",
       " 'fit_time': (0.9594085216522217,\n",
       "  1.0097758769989014,\n",
       "  1.0174012184143066,\n",
       "  0.9948179721832275,\n",
       "  1.013617753982544),\n",
       " 'test_time': (2.091670036315918,\n",
       "  2.2182188034057617,\n",
       "  2.112368583679199,\n",
       "  2.2716832160949707,\n",
       "  2.0942490100860596)}"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(algo2, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9321  0.9342  0.9419  0.9388  0.9338  0.9362  0.0036  \n",
      "Fit time          2.49    2.51    2.49    2.50    2.49    2.50    0.01    \n",
      "Test time         0.19    0.10    0.19    0.10    0.19    0.15    0.05    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.93205707, 0.93422931, 0.94194469, 0.93878855, 0.93380797]),\n",
       " 'fit_time': (2.4908695220947266,\n",
       "  2.511514663696289,\n",
       "  2.4877610206604004,\n",
       "  2.4956037998199463,\n",
       "  2.4919655323028564),\n",
       " 'test_time': (0.19041728973388672,\n",
       "  0.09635305404663086,\n",
       "  0.19119501113891602,\n",
       "  0.09602499008178711,\n",
       "  0.190643310546875)}"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(algo3, data, measures=['RMSE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "1.007549108056942\n",
      "{'k': 40, 'sim_options': {'name': 'pearson_baseline', 'user_based': False}}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'k': [10, 20, 30, 40], \n",
    "              'sim_options': {'name': ['cosine', 'pearson_baseline'], 'user_based': [False, False]\n",
    "              }}\n",
    "gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9645789297273387\n",
      "{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
