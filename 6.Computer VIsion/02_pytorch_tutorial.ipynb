{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ◽️ Pytorch Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## `torch.Tensors`\n",
    "* Tensorflow의 Tensor와 다르지 않다.\n",
    "  * Numpy의 ndarrays를 기본적으로 활용하고 있다.\n",
    "  * Numpy의 ndarrays의 대부분의 operation을 사용할 수 있도록 구성되어 있다.\n",
    "* Numpy의 operation은 CPU만을 이용해 느리지만 Tensor는 CUDA를 활용해 GPU를 이용하기 때문에 빠르게 연산을 진행할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T10:31:06.314276Z",
     "start_time": "2021-06-10T10:31:05.824373Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T04:03:31.063571Z",
     "start_time": "2021-06-10T04:03:31.038252Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T04:03:31.542125Z",
     "start_time": "2021-06-10T04:03:31.535498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T04:26:52.847382Z",
     "start_time": "2021-06-07T04:26:52.841899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T04:31:24.632337Z",
     "start_time": "2021-06-07T04:31:24.622307Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5, 5])\n",
      "torch.Size([1, 3, 5, 5])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "#img [batch, channel, h, w] pytorch\n",
    "\n",
    "# Construct a 1x3x5x5 matrix, uninitialized\n",
    "x = torch.Tensor(1,3,5,5)\n",
    "print(x.shape)\n",
    "\n",
    "# Construct a randomly initialized 1x3x5x5 matrix \n",
    "x = torch.rand(1,3,5,5)\n",
    "print(x.shape)\n",
    "\n",
    "# Construct a matrix with the list, [[3, 4, 5], [1, 2, 3]]\n",
    "x = torch.Tensor([[3, 4, 5], [1, 2, 3]])\n",
    "print(x.shape)\n",
    "\n",
    "# print the size of the last matrix\n",
    "\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✔️ dtype and device \n",
    " * dtype - Tensor의 데이터 타입\n",
    " * device - Tensor의 작업 위치 (cpu or cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T04:33:16.909198Z",
     "start_time": "2021-06-07T04:33:16.904039Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([[3, 4, 5], [1, 2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T04:34:12.107360Z",
     "start_time": "2021-06-07T04:34:12.099183Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4., 5.],\n",
      "        [1., 2., 3.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "## type cast the tensor 'x' to 'double or float64'\n",
    "## Todo\n",
    "x_ = x.double()\n",
    "x_ = x.type(torch.double)\n",
    "x_ = x.to(torch.double) # to : GPU로 값을 보내줌\n",
    "##\n",
    "print(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T04:36:58.916858Z",
     "start_time": "2021-06-07T04:36:58.910472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "## set the device of the tensor 'x' to gpu\n",
    "## TODO\n",
    "# (shall) > CUDA_VISIBLE_DEVICES=0 python main.py    : 0번 GPU만 쓰도록\n",
    "# (shall) > CUDA_VISIBLE_DEVICES=0,1 python main.py  : 0,1번 GPU 쓰도록\n",
    "# import os\n",
    "# os.env['CUDA_VISIBLE'] = 0\n",
    "\n",
    "# cuda란? GPU 프로그래밍을 하기위한 API\n",
    "device = torch.device('cuda')\n",
    "##\n",
    "x = x.to(device) # CPU -> GPU\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T04:41:20.272939Z",
     "start_time": "2021-06-07T04:41:18.221910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before \"to\" method\n",
      "torch.float64 cpu\n",
      "torch.float32 cpu\n",
      "torch.int32 cpu \n",
      "\n",
      "After \"to\" method\n",
      "torch.int32 cuda:0\n",
      "torch.int32 cuda:1\n",
      "torch.int32 cpu \n",
      "\n"
     ]
    }
   ],
   "source": [
    "device_0 = torch.device('cuda:0')\n",
    "device_1 = torch.device('cuda:1')\n",
    "\n",
    "x = torch.randn(4, 3, dtype=torch.float64)\n",
    "y = torch.randn(4, 3, dtype=torch.float32)\n",
    "z = torch.randint(0, 10, (4, 3), dtype=torch.int32)\n",
    "\n",
    "print('Before \"to\" method')\n",
    "\n",
    "print(x.dtype, x.device)\n",
    "print(y.dtype, y.device)\n",
    "print(z.dtype, z.device, '\\n')\n",
    "\n",
    "print('After \"to\" method')\n",
    "# to method with specific dtype and device \n",
    "z = z.to(device_1)\n",
    "x = x.to(dtype=torch.int32, device=device_0)\n",
    "\n",
    "# to method with some tensor \n",
    "y = y.to(z)\n",
    "z = z.to(device=\"cpu\")\n",
    "\n",
    "print(x.dtype, x.device)\n",
    "print(y.dtype, y.device)\n",
    "print(z.dtype, z.device, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✔️ Numpy-like tensor construction functions in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T10:33:15.923622Z",
     "start_time": "2021-06-10T10:33:15.899183Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: tensor([[5.0847e+25, 4.5567e-41, 5.0847e+25, 4.5567e-41, 4.4842e-44],\n",
      "        [0.0000e+00, 1.5695e-43, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [8.9683e-44, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]) \n",
      "\n",
      "2: tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]]) \n",
      "\n",
      "3: tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]]) \n",
      "\n",
      "4: tensor([[3.1415, 3.1415, 3.1415, 3.1415, 3.1415],\n",
      "        [3.1415, 3.1415, 3.1415, 3.1415, 3.1415],\n",
      "        [3.1415, 3.1415, 3.1415, 3.1415, 3.1415]]) \n",
      "\n",
      "5: tensor([0, 2, 4]) \n",
      "\n",
      "6: tensor([0.0000, 0.6250, 1.2500, 1.8750, 2.5000, 3.1250, 3.7500, 4.3750, 5.0000]) \n",
      "\n",
      "7: tensor([1.0000e-10, 1.0000e-05, 1.0000e+00, 1.0000e+05, 1.0000e+10]) \n",
      "\n",
      "8: tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]]) \n",
      "\n",
      "9: tensor([[7, 7, 3, 8, 9],\n",
      "        [4, 3, 3, 9, 8],\n",
      "        [6, 7, 9, 5, 4]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(3, 5)\n",
    "print('1:',x, '\\n')\n",
    "\n",
    "x = torch.zeros(3, 5)\n",
    "print('2:',x, '\\n')\n",
    "\n",
    "x = torch.ones(3, 5)\n",
    "print('3:',x, '\\n')\n",
    "\n",
    "x = torch.full((3, 5), 3.1415)\n",
    "print('4:',x, '\\n')\n",
    "\n",
    "x = torch.arange(0, 5, 2)\n",
    "print('5:',x, '\\n')\n",
    "\n",
    "y = torch.linspace(0, 5, 9)\n",
    "print('6:',y, '\\n')\n",
    "\n",
    "z = torch.logspace(-10, 10, 5)\n",
    "print('7:',z, '\\n')\n",
    "\n",
    "z = torch.eye(5)\n",
    "print('8:',z, '\\n')\n",
    "\n",
    "# Construct a 3 x 5 matrix with random value from uniform distribution, i.e. Uniform[0, 1)\n",
    "x = torch.rand(3, 5)\n",
    "\n",
    "# Construct a 3 x 5 matrix with random value from normal distribution, i.e. Normal(0, 1)\n",
    "x = torch.randn(3, 5)\n",
    "\n",
    "x = torch.randint(3, 10, (3, 5))\n",
    "print('9:',x, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✔️ `torch.*_like` and `torch.Tensor.new_*` methods\n",
    " * `*_like`: Tensor를 input으로 받아, Tensor 모양, type과 device를 가지는 matrix를 return.\n",
    "     * e.g. zeros_like, ones_like\n",
    " * `new_*`: Shape를 input으로 받아, Tensor와 같은 type과 device를 가지는 matrix를 return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T04:46:40.779226Z",
     "start_time": "2021-06-07T04:46:40.754280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 5, 5]) cuda:0\n",
      "torch.Size([2, 3]) cuda:0\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 3, 5, 5).type(torch.cuda.DoubleTensor)\n",
    "\n",
    "## TODO\n",
    "# construct zero-initialized tensor that has the shape of tensor 'x'\n",
    "y = torch.zeros_like(x) # zeros_like : y를 GPU로 바로 만들 수 있음\n",
    "print(y.size(), y.device)\n",
    "\n",
    "# Make zero-initialized 2x3 matrix with attributes of tensor 'x'\n",
    "y = x.new_zeros(2, 3)\n",
    "print(y.size(), y.device)\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✔️ Conversion between numpy and torch.Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T04:52:00.181971Z",
     "start_time": "2021-06-07T04:52:00.166034Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "\n",
      " [1. 1. 1. 1. 1.] \n",
      " tensor([1., 1., 1., 1., 1.], dtype=torch.float64) \n",
      " [1. 1. 1. 1. 1.]\n",
      "cuda:0\n",
      "\n",
      " [1. 1. 1. 1. 1.] \n",
      " tensor([1., 1., 1., 1., 1.], device='cuda:0', dtype=torch.float64) \n",
      " [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "print(b.device) # cpu\n",
    "c = b.numpy() # numpy는 cpu에서만 정의할 수 있음\n",
    "\n",
    "print('\\n', a, '\\n', b, '\\n', c)\n",
    "\n",
    "\n",
    "## TODO\n",
    "# convert gpu tensor 'b' into numpy tensor 'c'\n",
    "b = b.to('cuda:0')\n",
    "print(b.device) # gpu\n",
    "c = b.cpu().numpy()\n",
    "# c = b.to('cpu').numpy()\n",
    "\n",
    "## \n",
    "print('\\n', a, '\\n', b, '\\n', c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ✔️ Operations\n",
    "* Operations에도 여러가지 syntax가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T04:54:29.747303Z",
     "start_time": "2021-06-07T04:54:29.738011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "y = torch.rand(5, 3)\n",
    "\n",
    "## TODO: add tensors x and y using the specified method\n",
    "# +\n",
    "z1 = x + y\n",
    "# torch.add()\n",
    "z2 = torch.add(x,y)\n",
    "# torch.Tensor.add_()\n",
    "y.add_(x)\n",
    "# y+=x\n",
    "##\n",
    "\n",
    "print(torch.any((z1!=z2) != (z2!=y))) # false if all tensors are the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✔️ Useful tensor methods\n",
    "- `torch.Tensor.view()`, `torch.Tensor.reshape()`, `torch.Tensor.permute()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T08:13:11.346319Z",
     "start_time": "2021-06-08T08:13:11.334746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 2])\n",
      "tensor([[0, 0],\n",
      "        [0, 0]])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2],\n",
    "                  [3, 4]])   # 2x2 tensor\n",
    "y = torch.tensor([[[1, 3],\n",
    "                   [2, 4]]]) # 1x2x2 tensor \n",
    "print(y.size())\n",
    "\n",
    "## TODO: make (x-y_new).sum()=0 by changing y with view()[or reshape()] and permute()\n",
    "y_new = y.view(2,2)\n",
    "#y_new = y.reshape(2,2) 결과 같음\n",
    "#y_new = y.squeeze() 결과 같음\n",
    "\n",
    "y_new = y_new.permute(1,0) # 0번째와 1번째 차원의 순서바꿈\n",
    "# shape : b X c X h X w\n",
    "# shape : b X c X w X h\n",
    "# y_new.permute(0, 1, 3, 2) 위치를 바꿔줌\n",
    "\n",
    "print(x-y_new)\n",
    "print((x-y_new).sum())\n",
    "\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.Tensor.unsqueeze()`, `torch.Tensor.squeeze()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T08:21:00.029898Z",
     "start_time": "2021-06-08T08:21:00.019620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 5]) \n",
      "\n",
      "torch.Size([1, 2, 5]) \n",
      "\n",
      "torch.Size([2, 5]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 100x700x28\n",
    "x = torch.arange(0, 10) # [10]\n",
    "x = x.view(2,5) # 2x5\n",
    "\n",
    "## TODO\n",
    "#: make the shape of x to 2x1x5\n",
    "z = x.unsqueeze(dim=1)\n",
    "print(z.size(), '\\n')\n",
    "\n",
    "#: make the shape of x to 1x2x5\n",
    "z = x.unsqueeze(dim=0)\n",
    "print(z.size(), '\\n')\n",
    "\n",
    "#: remove dimension with size 1\n",
    "z = z.squeeze()\n",
    "print(z.size(), '\\n')\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- `torch.Tensor.expand()`, `torch.Tensor.repeat()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T08:28:16.528473Z",
     "start_time": "2021-06-08T08:28:16.512742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 700, 28])\n",
      "torch.Size([100, 28, 700])\n",
      "torch.Size([100, 28, 700])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(100, 700)\n",
    "x = x.unsqueeze(2).expand(100, 700, 28)\n",
    "print(x.shape)\n",
    "\n",
    "## TODO: expand the tensor 'x' to 100x28x700\n",
    "x = torch.randn(100, 700)\n",
    "\n",
    "# using .expand()\n",
    "x_ = x.unsqueeze(dim=1).expand(-1,28,-1)\n",
    "#x_ = x.view(100,1,700).expand(-1,28,-1)\n",
    "print(x_.shape)\n",
    "\n",
    "# using .repeat()\n",
    "x_ = x.unsqueeze(dim=1).repeat(1, 28, 1) # (100,1,700)을 몇번 반복할 건지?\n",
    "print(x_.shape)\n",
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T08:32:17.369057Z",
     "start_time": "2021-06-08T08:32:17.337347Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3]) torch.Size([5, 3])\n",
      "tensor([[6., 6., 6.],\n",
      "        [6., 6., 6.],\n",
      "        [6., 6., 6.],\n",
      "        [6., 6., 6.],\n",
      "        [6., 6., 6.]]) torch.Size([5, 3])\n",
      "tensor([[18., 18., 18., 18., 18.],\n",
      "        [18., 18., 18., 18., 18.],\n",
      "        [18., 18., 18., 18., 18.],\n",
      "        [18., 18., 18., 18., 18.],\n",
      "        [18., 18., 18., 18., 18.]]) torch.Size([5, 5])\n",
      "torch.Size([2, 64, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# multiplication\n",
    "x = torch.ones(5, 3)+1\n",
    "y = torch.ones(5, 3)+2\n",
    "z = x * y\n",
    "print(x.shape, y.shape)\n",
    "print(z, z.shape)\n",
    "\n",
    "# matrix multiplication\n",
    "z= torch.matmul(x, y.t())\n",
    "print(z, z.shape)\n",
    "\n",
    "# concatenation 많이 사용함!\n",
    "x = torch.ones(2,32,256,256)\n",
    "y = torch.ones(2,32,256,256)\n",
    "\n",
    "#x = x.unsqueeze(0)\n",
    "#y = y.unsqueeze(0)\n",
    "z = torch.cat([x, y], dim=1) # 2 x 64 x 256 x 256\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Tensor Quiz*\n",
    "- *CASENet: Deep Category-Aware Semantic Edge Detection, Z. Yu et al, CVPR2018* 논문에서 제시한 방법.\n",
    "![casenet](./resources/casenet.png \"casenet\")\n",
    "\n",
    "\n",
    "1. shape이 [4,5,4,4]인 tensor, `src`와 shape이 [4,2,4,4]인 *channel inserting* tensor, `ch_insert`가 있다.\n",
    "2. `ch_insert` tensor를 `src` tensor의 각 채널에 insert 하고 싶다 (그림 h 참고).\n",
    "3. `result` tensor의 shape은 [4,15,4,4] 이 나와야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T08:29:08.821013Z",
     "start_time": "2021-06-08T08:29:08.815727Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "src = torch.ones(4,5,4,4)\n",
    "ch_insert= torch.ones(4,2,4,4)*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "src_ = \n",
    "ch_insert_ = \n",
    "\n",
    "\n",
    "result = result.view(expand_dim[0],expand_dim[1]*(expand_dim[2]+1),expand_dim[3],expand_dim[4])\n",
    "##\n",
    "\n",
    "# result\n",
    "result_splits = list(torch.split(result, 3, dim=1))\n",
    "print('Correct' if not any([torch.any(result_splits[0] != split) for split in result_splits[1:]]) else 'Wrong')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## `torch.autograd`: automatic differentiation\n",
    "* Autograd package는 tensor가 사용할 수 있는 operation들의 gradient를 자동으로 계산해준다.\n",
    "* Tensor의 `requires_grad` attribute을 이용해 gradient의 계산여부를 결정할 수 있다.\n",
    "  * 계산이 완료된 이후에 `.backward()`를 호출하면 자동으로 gradient를 계산한다.\n",
    "  * `.grad` attribute를 통해 마찬가지로 gradient에 접근할 수 있다. \n",
    "  * `.grad_fn` attribute를 통해 해당 Variable이 어떻게 생성되었는지 확인할 수 있다.\n",
    "  \n",
    "  \n",
    "![Alt text](./resources/Variable.png \"Variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:51:16.102725Z",
     "start_time": "2021-06-09T08:51:16.093596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True) True\n"
     ]
    }
   ],
   "source": [
    "## .requires_grad\n",
    "x = torch.ones(2, 2, requires_grad=True) # requires_grad=Tru : 연산을 기록\n",
    "\n",
    "print(x, x.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:51:16.594621Z",
     "start_time": "2021-06-09T08:51:16.585343Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "<AddBackward0 object at 0x7fb82f629198>\n",
      "<MulBackward0 object at 0x7fb8d8d4d240>\n",
      "<MeanBackward0 object at 0x7fb82f629198>\n"
     ]
    }
   ],
   "source": [
    "## .grad_fn\n",
    "y = x + 2     \n",
    "z = y * y * 3 # forward하는 동안 grad가 쌓임\n",
    "out = z.mean()\n",
    "\n",
    "# .grad_fn exists for the tensor 'y', as it is created with an operation (addition),\n",
    "# however, x does not have one.\n",
    "print(x.grad_fn)\n",
    "print(y.grad_fn)\n",
    "print(z.grad_fn)\n",
    "print(out.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✔️ Gradients \n",
    "* `out.backward()`를 하면 `out`의 gradient 1로부터 back-propagation을 시작한다.\n",
    "* `.backward()`를 호출한 이후부터는 `.grad`를 통해 각 변수의 gradient를 출력할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:51:29.180907Z",
     "start_time": "2021-06-09T08:51:29.172226Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before : None\n",
      "After : tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "# out.backward() == out.backward(torch.Tensor([1.0]))\n",
    "\n",
    "x.grad=None\n",
    "out.grad=None\n",
    "\n",
    "print('Before :',x.grad)\n",
    "out.backward(retain_graph=True) # backward => autograd가 계산함 # retain_graph는 내부 버퍼들이 지워지는 것을 막음.\n",
    "print('After :',x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 실제로 Gradient 를 계산하면 다음과 같다.\n",
    "$$o = \\frac{1}{4}\\sum_{i} z_{i}$$ \n",
    "\n",
    "$$z_{i}=3(x_{i}+2)^{2}$$\n",
    "\n",
    "$$ \\frac{\\partial o}{\\partial x_{i}} = \\frac{3}{2}(x_{i} + 2) $$\n",
    "\n",
    "$$ \\frac{\\partial o}{\\partial x_{i}}|_{x_{i}=1} = 4.5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Trianing a Neural Network\n",
    "#### 1. Define a Network\n",
    "* `nn.Module` 을 inherit하는 class를 define한다.\n",
    "  * `__init__(self)`: 생성자, network에서 사용할 구조를 정의한다.\n",
    "  * `forward(self, x)`: x를 input으로 받는 network가 어떻게 작동해 어떤 output을 내놓을지 정의한다.\n",
    "  \n",
    "  ![convnet](./resources/mnist.png \"Variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>1단계 : nn.Module</b>  \n",
    "   nn.conv2d(), nn.linear(), nn.relu(), nn.sigmoid(), nn.maxpooling, nn.batchNorm  \n",
    "   nn.linear(FC)는 요즘 안씀(Transformer 사용), nn.sigmoid도 잘안씀  \n",
    "   instanceNorm  \n",
    "   \n",
    "- <b>2단계 : Dataset</b>  \n",
    "   경로를 주면 읽어주고 batch로 데이터를 준다  \n",
    "   Dataloader(Dataset, batchsize)\n",
    "\n",
    "- <b>3단계 : nn.optim</b>  \n",
    "   loss = MSE(out, gt)  \n",
    "   nn.optim(loss, weight).step()  \n",
    "   loop 돌면서 weight가 학습됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T05:00:14.664485Z",
     "start_time": "2021-06-10T05:00:12.590687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T05:06:29.371563Z",
     "start_time": "2021-06-10T05:06:29.355414Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "class Net(nn.Module): # nn.Module 상속\n",
    "    #__init__(self), forward(self, x) 반드시 있어야 한다.\n",
    "    def __init__(self): # 각 사용할 Layer들을 정의\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # 이 layer로 들어오는 input의채널 1, output 채널6 -> 커널 6개 가지고 있다\n",
    "                                        # self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "                                        # 각 채널의 special size가 5x5, 직사각은 튜플로 정의 ex. 5 -> (5,3)\n",
    "                                        # padding=0 일 경우 32x32 -> 28x28로 줄어듬\n",
    "                                        # padding=5//2로 넣으면 사이즈 같아짐 (kernel size//2)\n",
    "                                        # 1x32x32 -> 6x28x28\n",
    "        ## maxpooling\n",
    "        ## self.max_pool1 = nn.MaxPool2d(2, 2) # kernel_size : 2, stride : 2, forward에서 정의해도 됨\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) # kernel 16개 가지고 있다.\n",
    "                                         # 6x14x14 -> 16x10x10\n",
    "        \n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # 16x5x5 -> 120\n",
    "        self.fc2 = nn.Linear(120, 84)         # 120    -> 84\n",
    "        self.fc3 = nn.Linear(84, 10)          # 84     -> 10\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) # __init__에서 정의된 함수 가져다 씀 kernel_size = 2\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) # kernel_size = 2\n",
    "        \n",
    "        ## x -> [B, C, H, W] -> [B, C * H * W]\n",
    "        x = x.view(x.size(0), -1) # flatten되버림 (b, 16x5x5 -> b, 120)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) # softmax 사용안함 -> loss에서 logit형태로 받아서 사용함, loss 함수에 softmax가 들어있음\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T05:16:47.613369Z",
     "start_time": "2021-06-10T05:16:46.899961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 10 14:16:47 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.82       Driver Version: 440.82       CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 108...  Off  | 00000000:03:00.0  On |                  N/A |\r\n",
      "| 30%   47C    P8    13W / 250W |   1133MiB / 11175MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  GeForce GTX 108...  Off  | 00000000:04:00.0 Off |                  N/A |\r\n",
      "| 29%   35C    P8     9W / 250W |    842MiB / 11178MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1069      G   /usr/lib/xorg/Xorg                            18MiB |\r\n",
      "|    0      1190      G   /usr/bin/gnome-shell                          70MiB |\r\n",
      "|    0      5103      G   /usr/lib/xorg/Xorg                           108MiB |\r\n",
      "|    0      5215      G   /usr/bin/gnome-shell                          51MiB |\r\n",
      "|    0      5628      G   ...AAAAAAAAAAAAAAgAAAAAAAAA --shared-files    21MiB |\r\n",
      "|    0      6461      C   python                                       135MiB |\r\n",
      "|    0     24017      C   .../piai/anaconda3/envs/edu_env/bin/python   713MiB |\r\n",
      "|    1      6461      C   python                                       135MiB |\r\n",
      "|    1     24017      C   .../piai/anaconda3/envs/edu_env/bin/python   695MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T05:28:56.359884Z",
     "start_time": "2021-06-10T05:28:56.304022Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: DataParallel(\n",
      "  (module): Net(\n",
      "    (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "    (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ") \n",
      "\n",
      "module.conv1.weight: torch.Size([6, 1, 5, 5]), cuda:0\n",
      "module.conv1.bias: torch.Size([6]), cuda:0\n",
      "module.conv2.weight: torch.Size([16, 6, 5, 5]), cuda:0\n",
      "module.conv2.bias: torch.Size([16]), cuda:0\n",
      "module.fc1.weight: torch.Size([120, 400]), cuda:0\n",
      "module.fc1.bias: torch.Size([120]), cuda:0\n",
      "module.fc2.weight: torch.Size([84, 120]), cuda:0\n",
      "module.fc2.bias: torch.Size([84]), cuda:0\n",
      "module.fc3.weight: torch.Size([10, 84]), cuda:0\n",
      "module.fc3.bias: torch.Size([10]), cuda:0\n",
      "\n",
      "2: 10 \n",
      "\n",
      "3: torch.Size([6, 1, 5, 5]) \n",
      "\n",
      "4: tensor([[-0.0149,  0.0436,  0.0307, -0.0459,  0.0425, -0.0980,  0.0240, -0.0323,\n",
      "          0.0306, -0.1031]], device='cuda:0', grad_fn=<GatherBackward>) \n",
      "\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             156\n",
      "            Conv2d-2            [-1, 6, 28, 28]             156\n",
      "            Conv2d-3           [-1, 16, 10, 10]           2,416\n",
      "            Conv2d-4           [-1, 16, 10, 10]           2,416\n",
      "            Linear-5                  [-1, 120]          48,120\n",
      "            Linear-6                  [-1, 120]          48,120\n",
      "            Linear-7                   [-1, 84]          10,164\n",
      "            Linear-8                   [-1, 84]          10,164\n",
      "            Linear-9                   [-1, 10]             850\n",
      "           Linear-10                   [-1, 10]             850\n",
      "              Net-11                   [-1, 10]               0\n",
      "              Net-12                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 123,412\n",
      "Trainable params: 123,412\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.10\n",
      "Params size (MB): 0.47\n",
      "Estimated Total Size (MB): 0.57\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Declare a network\n",
    "net = nn.DataParallel(Net().to(torch.device('cuda'))) # gpu multi로 사용하기 -> cuda :0으로 모인다 / cpu도 병렬로 사용가능\n",
    "# net = Net().to(torch.device('cuda')) # gpu single로 사용\n",
    "print('1:',net, '\\n')\n",
    "\n",
    "# The learnable parameters of a model are returned by net.parameters()\n",
    "params = list(net.parameters())\n",
    "\n",
    "for k,v in dict(net.named_parameters()).items(): # 전체 param 출력\n",
    "    print('{}: {}, {}'.format(k, v.size(), v.device))\n",
    "    \n",
    "print('\\n2:',len(params), '\\n')\n",
    "print('3:',params[0].size(), '\\n')\n",
    "\n",
    "# The input to the forward is a tensor, and so is the output\n",
    "input = torch.randn(1, 1, 32, 32).to(torch.device('cuda')) # input도 network랑 같은 device에 있어야한다. (cpu or gpu)\n",
    "\n",
    "out = net(input)\n",
    "print('4:',out, '\\n')\n",
    "\n",
    "summary(net,(1,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define a Loss Function\n",
    "* Loss function은 (output, target) 을 input으로 받아 그 차이를 return한다.\n",
    "* 직접 구현할 수도 있지만 대부분의 일반적인 loss는 대부분 `torch.nn` package에 구현되어있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T05:29:00.352646Z",
     "start_time": "2021-06-10T05:29:00.342006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(38.7511, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "<MseLossBackward object at 0x7f95dca90278>\n"
     ]
    }
   ],
   "source": [
    "# For example\n",
    "target = torch.arange(1, 11, dtype=torch.float).unsqueeze(0).to(torch.device('cuda')) # a dummy target, for example\n",
    "                                                                                      # .to(torch.device('cuda') == .cuda()  \n",
    "criterion = nn.MSELoss() # loss\n",
    "\n",
    "loss = criterion(out, target)\n",
    "#위의 모델에서 나온 out과 target의 MSE를 loss에서 구함\n",
    "\n",
    "print(loss) # loss를 출력 = 1번 iter 계산함\n",
    "# You can follow loss in the backward direction, using it's .grad_fn attribute\n",
    "print(loss.grad_fn)  # MSELoss\n",
    "# print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "# print(loss.grad_fn.next_functions[0][0].next_functions[1][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Training the Network\n",
    "- Back propagation\n",
    "    * Back-propagation을 위해서는 여러번 언급했듯이 loss.backward()를 이용한다.\n",
    "    * net.zero_grad()를 이용해 먼저 모든 parameter의 gradient buffer에 0을 대입한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T05:29:01.488848Z",
     "start_time": "2021-06-10T05:29:01.475740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "None\n",
      "conv1.bias.grad after backward\n",
      "tensor([ 0.0277,  0.0791,  0.0150, -0.0024,  0.0964, -0.0439], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.module.conv1.bias.grad) # data parallel로 묶어줘서 net.module.~~로 바뀜\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.module.conv1.bias.grad) # gradient 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Update the weights (manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate) # for문을 통한 계산방법인데 optim을 쓸거라서 사용안할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T05:31:39.081149Z",
     "start_time": "2021-06-10T05:31:39.051555Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time \n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "output = net(input)\n",
    "\n",
    "# loss\n",
    "loss = criterion(output, target)\n",
    "\n",
    "# update\n",
    "optimizer.zero_grad()   # zero the gradient buffers 쌓여있는 gradient를 0으로 만듬. 안넣으면 기존값이 계속 남아있음\n",
    "loss.backward() # 0이었던 param에 gradient가 생김\n",
    "optimizer.step() # gradient가 update됨   # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✔️ **Network with CUDA & Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T05:38:22.045048Z",
     "start_time": "2021-06-10T05:38:18.327945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 99/100][itr 8/9] Loss: 0.038977585732936864\n",
      " [0.9590768, 1.9422506, 2.9382508, 3.8804264, 4.887569, 5.861527, 6.8171654, 7.8215866, 8.81944, 9.790336]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "total_epoch = 100\n",
    "batch_size = 12\n",
    "\n",
    "## 0. define a network\n",
    "net = Net().to(device)\n",
    "\n",
    "## 1. define loss and optimizer\n",
    "MSE = nn.MSELoss()\n",
    "optim = torch.optim.SGD(net.parameters(), lr=1e-4)\n",
    "\n",
    "## 2. training loop\n",
    "for epoch in range(total_epoch):\n",
    "    # 2-1. get input and target\n",
    "    input = torch.randn(100, 1, 32, 32).to(device) # 32x32 이미지가 100장\n",
    "    target = torch.arange(1, 11, dtype=torch.float).view(1, 10).repeat(100, 1).to(device) # gt는 1부터 10짜리 array\n",
    "                                                                                          # gt(ground truth) = y_true\n",
    "    # 100 x [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "    batch_idx = np.array_split(range(input.size(0)), np.ceil(input.size(0)/batch_size))\n",
    "    for itr, b_idx in enumerate(batch_idx): # 12장씩 가져오는 for문\n",
    "        # 2-2. sample batch\n",
    "        input_b = input[b_idx]\n",
    "        target_b = target[b_idx]\n",
    "        \n",
    "        # 2-2. run network\n",
    "        out = net(input_b)\n",
    "\n",
    "        # 2-3. compute loss\n",
    "        loss = MSE(out, target_b)\n",
    "\n",
    "        # 2-4. compute gradient\n",
    "        optim.zero_grad() # gradient 지워주고\n",
    "        loss.backward() # gradient 구하고\n",
    "\n",
    "        # 2-5. update network\n",
    "        optim.step() # 구한 gradient로 학습한다\n",
    "    \n",
    "        print('\\r[Epoch {}/{}][itr {}/{}] Loss: {}'.format(epoch, total_epoch, itr, len(batch_idx), loss), end='')\n",
    "\n",
    "print('\\n', [val for val in out[0].detach().cpu().numpy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Datasets and DataLoader\n",
    "* Tensorflow와 가장 크게 다른 점. \n",
    "* Tensorflow에서는 dataset과 loader의 form이 구체적이지 않았으나, PyTorch에서는 dataset과 DataLoader의 구체적인 form을 제공하고 쉽게 Batch를 만들 수 있도록 한다.\n",
    "  * `torch.utils.data.Dataset`: Neural Network에 사용하고자 하는 dataset에서 이미지를 뽑아주는 역할을 하는 class. 여기서 image의  pre-processing을 할 수 있다.\n",
    "  * `torch.utils.data.DataLoader`: Dataset을 통해 전처리된 이미지를 batch size 개수만큼 뽑아 batch를 만들어주는 역할을 하는 class. 이미지의 순서를 섞는 등의 효과를 사용할 수도 있다.\n",
    "  * 직접 구현하는 것도 가능하지만 다음 시간에 활용하고자 한다.\n",
    "* 유명한 dataset의 경우 `torchvision.datasets`에서 기본적으로 제공한다. \n",
    "  * MNIST, MSCOCO, LSUN, ImageFolder, Imagenet-12, CIFAR, STL10, SVHN, PhotoTour\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✔️ Transform\n",
    "* Data augmentation을 위한 변환을 자동으로 수행해주는 함수\n",
    "* `torchvision.transforms`에 위치하고 있음\n",
    "  * 역시 직접 구현도 가능하다. 이도 역시 다음 시간에 활용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T07:07:17.534644Z",
     "start_time": "2021-06-10T07:07:17.530357Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T07:14:48.422399Z",
     "start_time": "2021-06-10T07:14:38.453514Z"
    },
    "code_folding": [],
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-06-10 16:14:39--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
      "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
      "접속 www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... 접속됨.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
      "--2021-06-10 16:14:39--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
      "접속 www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... 접속됨.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/x-gzip]\n",
      "Saving to: ‘MNIST.tar.gz’\n",
      "\n",
      "MNIST.tar.gz            [        <=>         ]  33.20M  6.95MB/s    in 6.2s    \n",
      "\n",
      "2021-06-10 16:14:46 (5.32 MB/s) - ‘MNIST.tar.gz’ saved [34813078]\n",
      "\n",
      "MNIST/\n",
      "MNIST/raw/\n",
      "MNIST/raw/train-labels-idx1-ubyte\n",
      "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "MNIST/raw/t10k-labels-idx1-ubyte\n",
      "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "MNIST/raw/train-images-idx3-ubyte\n",
      "MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "MNIST/raw/t10k-images-idx3-ubyte\n",
      "MNIST/raw/train-images-idx3-ubyte.gz\n",
      "MNIST/processed/\n",
      "MNIST/processed/training.pt\n",
      "MNIST/processed/test.pt\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose( # transforms : Tensor로 바꾸고 Normalize한다.\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(0.5, 0.5)]) # 0~1사이의 이미지를 -1~1사이의 이미지로 변경(0.5빼고, 0.5나눔)\n",
    "#      transforms.Normalize((0.5,), (0.5,))]) # dimension상 error는 tuple로 묶어주면됨\n",
    "\n",
    "\n",
    "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "!tar -zxvf MNIST.tar.gz -C ./data\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, # data 가공, 경로에서 data를 찾아오고, train 데이터만 가져오고 \n",
    "                                      download=True, transform=transform) # 없으면 download하고 transform도 알아서해줌\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                      download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, # trainset이 가공한 dataset에서 이미지를 8장씩 읽는다.\n",
    "                                         shuffle=True, num_workers=2) # batch를 랜덤하게 할 수있다. Thread 2개로 일함.\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(trainset, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T07:32:29.365806Z",
     "start_time": "2021-06-10T07:32:29.086048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3     9     4     1     1     6     3     1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next() # .next() 다음것 가져오기\n",
    "#print(images.shape) # \n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % labels[j].item() for j in range(8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T07:18:37.900074Z",
     "start_time": "2021-06-10T07:18:36.925024Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==0.12.0\n",
      "astunparse==1.6.3\n",
      "attrs==19.3.0\n",
      "backcall==0.2.0\n",
      "bleach==3.1.5\n",
      "blinker==1.4\n",
      "boto==2.49.0\n",
      "boto3==1.17.18\n",
      "botocore==1.20.18\n",
      "cachetools==4.1.0\n",
      "certifi==2020.12.5\n",
      "cffi==1.14.0\n",
      "chardet==3.0.4\n",
      "click==7.1.2\n",
      "cryptography==2.9.2\n",
      "cvxopt==1.2.6\n",
      "cvxpy==1.0.21\n",
      "cycler==0.10.0\n",
      "decorator==4.4.2\n",
      "defusedxml==0.6.0\n",
      "deprecation==2.1.0\n",
      "dill==0.3.1.1\n",
      "ecos==2.0.7.post1\n",
      "entrypoints==0.3\n",
      "fancyimpute==0.5.5\n",
      "fastcache==1.1.0\n",
      "flatbuffers==1.12\n",
      "future==0.18.2\n",
      "gast==0.3.3\n",
      "gensim==3.8.0\n",
      "google-api-core==1.22.2\n",
      "google-auth==1.14.1\n",
      "google-auth-oauthlib==0.4.1\n",
      "google-cloud-core==1.6.0\n",
      "google-cloud-storage==1.36.1\n",
      "google-crc32c==1.1.2\n",
      "google-pasta==0.2.0\n",
      "google-resumable-media==1.2.0\n",
      "googleapis-common-protos==1.52.0\n",
      "graphviz==0.16\n",
      "grpcio==1.32.0\n",
      "h5py==2.10.0\n",
      "idna==2.9\n",
      "importlib-metadata==1.6.1\n",
      "intervaltree==3.1.0\n",
      "ipykernel==5.3.0\n",
      "ipython==7.15.0\n",
      "ipython-genutils==0.2.0\n",
      "ipywidgets==7.5.1\n",
      "jedi==0.17.0\n",
      "Jinja2==2.11.2\n",
      "jmespath==0.10.0\n",
      "joblib==1.0.1\n",
      "jsonpickle==2.0.0\n",
      "jsonschema==3.2.0\n",
      "jupyter-client==6.1.3\n",
      "jupyter-contrib-core==0.3.3\n",
      "jupyter-contrib-nbextensions==0.5.1\n",
      "jupyter-core==4.6.3\n",
      "jupyter-highlight-selected-word==0.2.0\n",
      "jupyter-latex-envs==1.4.6\n",
      "jupyter-nbextensions-configurator==0.4.1\n",
      "Keras==2.4.3\n",
      "Keras-Preprocessing==1.1.2\n",
      "kiwisolver==1.2.0\n",
      "knnimpute==0.1.0\n",
      "lxml==4.6.2\n",
      "Markdown==3.1.1\n",
      "MarkupSafe==1.1.1\n",
      "matplotlib==3.0.2\n",
      "mistune==0.8.4\n",
      "mkl-fft==1.0.15\n",
      "mkl-random==1.1.1\n",
      "mkl-service==2.3.0\n",
      "mpmath==1.2.1\n",
      "multidict==5.1.0\n",
      "multiprocess==0.70.9\n",
      "nbconvert==5.6.1\n",
      "nbformat==5.0.7\n",
      "networkx==2.2\n",
      "notebook==6.0.3\n",
      "numpy==1.19.5\n",
      "oauthlib==3.1.0\n",
      "olefile==0.46\n",
      "open3d==0.10.0.0\n",
      "opencv-python==4.4.0.42\n",
      "opt-einsum==3.3.0\n",
      "osqp==0.6.1\n",
      "packaging==20.4\n",
      "pandas==1.2.1\n",
      "pandocfilters==1.4.2\n",
      "parso==0.7.0\n",
      "patsy==0.5.1\n",
      "pexpect==4.8.0\n",
      "pickleshare==0.7.5\n",
      "Pillow==7.1.2\n",
      "pm4py==2.2.1\n",
      "prometheus-client==0.8.0\n",
      "prompt-toolkit==3.0.5\n",
      "protobuf==3.11.4\n",
      "ptyprocess==0.6.0\n",
      "PuLP==2.1\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.7\n",
      "pycparser==2.20\n",
      "pydotplus==2.0.2\n",
      "Pygments==2.6.1\n",
      "PyJWT==1.7.1\n",
      "pyOpenSSL==19.1.0\n",
      "pyparsing==2.4.7\n",
      "pyrsistent==0.16.0\n",
      "PySocks==1.7.1\n",
      "python-dateutil==2.8.1\n",
      "pytz==2020.1\n",
      "pyvis==0.1.9\n",
      "PyYAML==5.4.1\n",
      "pyzmq==18.1.1\n",
      "requests==2.23.0\n",
      "requests-oauthlib==1.3.0\n",
      "rsa==4.0\n",
      "s3transfer==0.3.4\n",
      "scikit-learn==0.24.1\n",
      "scipy==1.4.1\n",
      "scs==2.0.2\n",
      "seaborn==0.11.1\n",
      "Send2Trash==1.5.0\n",
      "six==1.15.0\n",
      "smart-open==4.2.0\n",
      "sortedcontainers==2.3.0\n",
      "statsmodels==0.12.1\n",
      "StringDist==1.0.9\n",
      "sympy==1.7.1\n",
      "tensorboard==2.5.0\n",
      "tensorboard-data-server==0.6.0\n",
      "tensorboard-plugin-wit==1.6.0\n",
      "tensorflow==2.2.0\n",
      "tensorflow-estimator==2.4.0\n",
      "tensorflow-gpu==2.4.1\n",
      "termcolor==1.1.0\n",
      "terminado==0.8.3\n",
      "testpath==0.4.4\n",
      "threadpoolctl==2.1.0\n",
      "torch==1.7.1\n",
      "torchaudio==0.7.2\n",
      "torchsummary==1.5.1\n",
      "torchvision==0.6.0a0+82fd1c8\n",
      "tornado==6.0.4\n",
      "tqdm==4.58.0\n",
      "traitlets==4.3.3\n",
      "typing-extensions==3.7.4.3\n",
      "urllib3==1.25.8\n",
      "wcwidth==0.2.4\n",
      "webencodings==0.5.1\n",
      "Werkzeug==1.0.1\n",
      "widgetsnbextension==3.5.1\n",
      "wrapt==1.12.1\n",
      "yarl==1.5.1\n",
      "zipp==3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-10T07:23:09.431663Z",
     "start_time": "2021-06-10T07:23:09.424284Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edu_env",
   "language": "python",
   "name": "edu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
